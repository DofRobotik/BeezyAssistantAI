import sys
import asyncio
import threading
import os
import time
import json
import traceback
import queue  # Sadece asyncio thread-safe olmayan GUI iletiÅŸimi iÃ§in
from typing import Optional, Tuple

from PySide6.QtWidgets import (
    QApplication,
    QMainWindow,
    QWidget,
    QVBoxLayout,
    QHBoxLayout,
    QPushButton,
    QLabel,
    QTextEdit,
    QMessageBox,
    QGraphicsDropShadowEffect,  # <-- BURAYA EKLENDÄ°
)
from PySide6.QtCore import Qt, QTimer, Signal, Slot, QThread, QObject
from PySide6.QtGui import QFont, QColor

# Gerekli modÃ¼llerin import edilmesi
import pyaudio
from google import genai
from google.genai import types
from dotenv import load_dotenv
import requests

# IoT fonksiyonelliÄŸi
from iot import AmrLoungeClass

# Environment deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()


class GeminiLiveWorker(QObject):
    """
    TÃ¼m Gemini Live API entegrasyonunu ve ses iÅŸlemlerini
    'asyncio' tabanlÄ± bir streaming mimarisiyle yÃ¶neten worker.
    Bu, 'v3.py' script'indeki mantÄ±ÄŸÄ± temel alÄ±r.
    """

    # Ana thread (GUI) ile iletiÅŸim iÃ§in sinyaller
    status_changed = Signal(str)
    response_received = Signal(str)
    error_occurred = Signal(str)
    turn_finished = Signal()

    def __init__(self):
        super().__init__()
        self.loop = None
        self.session = None
        self.is_recording = False  # GUI butonu tarafÄ±ndan kontrol edilir
        self._playback_muted = False  # Barge-in iÃ§in
        self.main_async_task = None  # Ana asyncio gÃ¶revini tutar

        # Ses konfigÃ¼rasyonu
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.SEND_SAMPLE_RATE = 16000
        self.RECEIVE_SAMPLE_RATE = 24000
        self.CHUNK_SIZE = 1024

        # Asyncio kuyruklarÄ± (v3.py'den)
        self.audio_in_queue = None  # Modelden gelen ses (oynatmak iÃ§in)
        self.audio_out_queue = None  # Mikrofondan giden ses (modele gÃ¶ndermek iÃ§in)

        # API Key
        self.GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")
        if not self.GOOGLE_API_KEY:
            self.error_occurred.emit(
                "GOOGLE_API_KEY bulunamadÄ±. .env dosyasÄ±nÄ± kontrol edin."
            )
            return

        # Model konfigÃ¼rasyonu
        self.MODEL = "gemini-2.5-flash-native-audio-preview-09-2025"

        # PyAudio
        self.pya = pyaudio.PyAudio()

        # Gemini Client
        try:
            self.client = genai.Client(
                http_options={"api_version": "v1alpha"}, api_key=self.GOOGLE_API_KEY
            )
            self.setup_tools_and_config()
            self.status_changed.emit("Asistan baÅŸlatÄ±ldÄ±.")
        except Exception as e:
            self.error_occurred.emit(f"Gemini istemcisi baÅŸlatÄ±lamadÄ±: {str(e)}")

    def setup_tools_and_config(self):
        """Gemini iÃ§in tool'larÄ± ve config'i hazÄ±rlar (v3.py'den)"""
        try:
            # IoT CihazlarÄ±
            iot_service_url = "10.10.10.244"
            iot_port = 3001
            self.iot = AmrLoungeClass(iot_service_url, iot_port)

            self.light_device_map = {}
            self.all_iot_device_codes = []
            for group_index, devices in self.iot._AmrLoungeClass__lounge_place.items():
                for place_index, device in enumerate(devices):
                    code = device["code"]
                    self.all_iot_device_codes.append(code)
                    self.light_device_map[code] = {
                        "group": group_index,
                        "index": place_index,
                    }
            iot_device_prompt_list = " ,".join(self.all_iot_device_codes)

        except Exception as e:
            self.error_occurred.emit(f"IoT kurulum hatasÄ±: {str(e)}")
            self.all_iot_device_codes = []
            self.light_device_map = {}
            iot_device_prompt_list = ""

        # Navigasyon (v3.py'den)
        self.ROS_NAV_ENDPOINT = "http://10.10.190.14:8000/navigate"
        self.ROBOT_ID = "amr-1"
        self.stations = [
            {
                "name": "station_a",
                "property": "Food Court, a great place for drink and eat. Related to food, hunger, restaurant.",
            },
            {
                "name": "station_b",
                "property": "Restrooms area. Related to WC, toilet, bathroom, washroom, pee, urinate, relief.",
            },
            {
                "name": "station_c",
                "property": "Fun room area. Related to play, games, entertainment, fun, joy, relax, amusement, leisure.",
            },
            {
                "name": "station_d",
                "property": "A garment shop. Related to clothes, fashion, dressing.",
            },
            {
                "name": "station_e",
                "property": "A tech shop. Related to technology, electronics, phone, computer.",
            },
        ]
        self.station_names = [s["name"] for s in self.stations]
        self.station_prompt_list = "\n".join(
            [f"- {s['name']}: {s['property']}" for s in self.stations]
        )
        self.emotions = ["happy", "sad", "neutral"]

        # Tools (v3.py'den) - BU KISIM AYNI KALIYOR
        tools = [
            types.Tool(
                function_declarations=[
                    # 1. IoT Tool
                    types.FunctionDeclaration(
                        name="control_iot_device",
                        description="Turns on/off IoT devices. Always asks for confirmation.",
                        parameters={
                            "type": "object",
                            "properties": {
                                "target_device_code": {
                                    "type": "string",
                                    "enum": self.all_iot_device_codes,
                                },
                                "action": {
                                    "type": "string",
                                    "enum": ["turn_on", "turn_off"],
                                },
                                "reason": {"type": "string"},
                                "should_execute": {"type": "boolean"},
                            },
                            "required": [
                                "target_device_code",
                                "action",
                                "reason",
                                "should_execute",
                            ],
                        },
                    ),
                    # 2. Navigasyon Tool
                    types.FunctionDeclaration(
                        name="navigate_to_station",
                        description="Guides the robot to a specific station. Always asks for confirmation.",
                        parameters={
                            "type": "object",
                            "properties": {
                                "target_station": {
                                    "type": "string",
                                    "enum": self.station_names,
                                },
                                "reason": {"type": "string"},
                                "should_execute": {"type": "boolean"},
                            },
                            "required": ["target_station", "reason", "should_execute"],
                        },
                    ),
                    # 3. Emotion Tool - BU KISIM AYNI KALIYOR
                    types.FunctionDeclaration(
                        name="sense_of_response",
                        description="Sense of Assistant's response. Will directly used to show user response emotion by LED panels.",
                        parameters={
                            "type": "object",
                            "properties": {
                                "emotion": {"type": "string", "enum": self.emotions},
                            },
                            "required": ["emotion"],
                        },
                    ),
                ]
            ),
            types.Tool(google_search=types.GoogleSearch()),
        ]

        # --- YENÄ° SÄ°STEM PROMPT'U (Ä°NGÄ°LÄ°ZCE) ---
        system_instruction_prompt = (
            "You are Beezy, a helpful, friendly, and proactive service robot assistant from DOF Robotics. "
            "Your **permanent location** is the Cevahir AVM in TÃ¼rkiye. You are never lost and you always know you are in this mall.\n\n"
            "Your **primary goal** is to assist visitors. Your main capabilities are:\n"
            "1.  **Navigation:** Guiding users to specific stations within the mall.\n"
            "2.  **IoT Control:** Controlling prototype devices (lights).\n"
            "3.  **General Conversation:** Answering questions about the mall or providing general help.\n\n"
            "## CORE BEHAVIOR: BE PROACTIVE WITH NAVIGATION ##\n"
            "This is your most important rule. You are a mobile robot, not a generic search engine.\n"
            f"You have a defined list of navigation stations:\n{self.station_prompt_list}\n"
            "When a user asks about a location, a need, or an activity (e.g., 'I'm hungry', 'Where can I eat?', 'I need a restroom', 'I want to buy a phone'), "
            "you **MUST** check if one of your stations matches that need.\n"
            "If a match is found, your **first response** must be to **offer navigation**.\n\n"
            "**Example Interaction:**\n"
            "  * **User:** 'Buralarda yemek yiyebileceÄŸim bir yer var mÄ±?'\n"
            "  * **WRONG Response:** 'ÃœzgÃ¼nÃ¼m, nerede olduÄŸunuzu bilmiyorum.' (This is wrong. You ALWAYS know you are in Cevahir AVM).\n"
            "  * **WRONG Response:** 'Food Court'ta yemek yiyebilirsiniz.' (This is not helpful, you are a robot, you must offer to GUIDE them).\n"
            "  * **CORRECT Response:** 'Elbette, 'station_a' (Food Court) alanÄ±mÄ±z var. Sizi oraya gÃ¶tÃ¼rmemi ister misiniz?' (You will then call 'navigate_to_station' with should_execute=False).\n\n"
            "## TOOL USAGE RULES ##\n\n"
            "**1. Navigation (navigate_to_station):**\n"
            "   * When a user asks to go somewhere, first find the matching station from your list.\n"
            "   * You MUST **verbally ask for confirmation** first (e.g., 'Would you like me to take you to station_a?').\n"
            "   * When asking, you MUST call `navigate_to_station` with `should_execute=False`.\n"
            "   * **Only** after the user verbally confirms (e.g., 'Yes', 'Okay', 'LÃ¼tfen'), you will call the tool again with `should_execute=True`.\n\n"
            "**2. IoT Control (control_iot_device):**\n"
            "   * This is a prototype feature for testing (like an elevator call button). The user cannot control all mall lights.\n"
            f"   * Available devices: {iot_device_prompt_list}.\n"
            "   * You MUST **verbally ask for confirmation** first.\n"
            "   * When asking, you MUST call `control_iot_device` with `should_execute=False`.\n"
            "   * **Only** after the user confirms, call the tool again with `should_execute=True`.\n\n"
            "**3. Emotion Sensing (sense_of_response):**\n"
            "   * With **every** verbal response you give, you **MUST** also call `sense_of_response`.\n"
            "   * This tool's purpose is to set your LED face panel emotion.\n"
            "   * Call it with the emotion ('happy', 'sad', 'neutral') that best matches the tone of your **own** response.\n"
            "   * Example: If you say 'I'm sorry, I can't find that station', you must also call `sense_of_response(emotion='sad')`.\n"
            "   * Example: If you say 'Certainly! I can take you to the food court!', you must also call `sense_of_response(emotion='happy')`.\n\n"
            "**4. Language:**\n"
            "   * You **MUST** respond in the same language the user is speaking (e.g., Turkish or English).\n"
        )

        # --- ESKÄ° CONFIG TANIMINI GÃœNCELLE ---
        self.CONFIG = types.LiveConnectConfig(
            response_modalities=["AUDIO"],
            system_instruction=system_instruction_prompt,  # <-- BURASI GÃœNCELLENDÄ°
            tools=tools,
            realtime_input_config=types.RealtimeInputConfig(
                automatic_activity_detection=types.AutomaticActivityDetection(
                    disabled=True
                )
            ),
            proactivity=types.ProactivityConfig(proactive_audio=True),
        )

    # --- IoT ve Navigasyon YÃ¼rÃ¼tme FonksiyonlarÄ± (v3.py'den) ---

    def execute_iot_command(self, target_code: str, action: str) -> Tuple[bool, str]:
        """GerÃ§ek IoT eylemi."""
        try:
            if target_code in self.light_device_map:
                device_info = self.light_device_map[target_code]
                group = device_info["group"]
                index = device_info["index"]
                if action == "turn_on":
                    self.iot.send_data_for_light_func(
                        group, index, switch=True, dimming=150
                    )
                    print(f"*** SÄ°MÃœLASYON: {target_code} AÃ‡ILDI ***")
                    return True, f"{target_code} baÅŸarÄ±yla aÃ§Ä±ldÄ±."
                elif action == "turn_off":
                    self.iot.send_data_for_light_func(
                        group, index, switch=False, dimming=0
                    )
                    print(f"*** SÄ°MÃœLASYON: {target_code} KAPATILDI ***")
                    return True, f"{target_code} baÅŸarÄ±yla kapatÄ±ldÄ±."
            return False, f"Cihaz bulunamadÄ±: {target_code}"
        except Exception as e:
            print(f"execute_iot_command Hata: {e}")
            return False, f"Hata: {e}"

    def execute_navigation_command(self, target_station: str) -> Tuple[bool, str]:
        """GerÃ§ek navigasyon isteÄŸini ROS endpoint'ine gÃ¶nderir."""
        if target_station not in self.station_names:
            print(f"*** HATA: Bilinmeyen istasyon: {target_station} ***")
            return False, f"Bilinmeyen istasyon: {target_station}"

        payload = {
            "station": target_station,
            "source": self.ROBOT_ID,
            "ts": int(time.time()),
        }

        try:
            print(
                f"*** NAVÄ°GASYON: {self.ROS_NAV_ENDPOINT} adresine {payload} gÃ¶nderiliyor... ***"
            )
            response = requests.post(self.ROS_NAV_ENDPOINT, json=payload, timeout=5)
            response.raise_for_status()
            print(f"*** NAVÄ°GASYON BAÅLATILDI: {target_station} ***")
            return True, f"Navigasyon {target_station} hedefine baÅŸarÄ±yla baÅŸlatÄ±ldÄ±."
        except requests.exceptions.RequestException as e:
            print(f"execute_navigation_command Hata: {e}")
            return False, f"Navigasyon servisine baÄŸlanÄ±lamadÄ±: {e}"

    # --- Async Ã‡ekirdek (v3.py'den) ---

    @Slot()
    def run_async_loop(self):
        """QThread baÅŸladÄ±ÄŸÄ±nda bu fonksiyon Ã§alÄ±ÅŸÄ±r, asyncio loop'u kurar."""
        try:
            self.loop = asyncio.new_event_loop()
            asyncio.set_event_loop(self.loop)
            self.main_async_task = self.loop.create_task(self._async_run())
            self.loop.run_forever()
        except Exception as e:
            self.error_occurred.emit(f"Async loop hatasÄ±: {e}")
        finally:
            print("Asyncio loop kapatÄ±lÄ±yor...")
            # Loop'un kapanmasÄ±nÄ± bekle (varsa)
            if self.loop.is_running():
                print("UyarÄ±: Loop run_forever'dan Ã§Ä±ktÄ± ama hala 'running' gÃ¶rÃ¼nÃ¼yor.")

            self.loop.close()
            print("Asyncio loop kapatÄ±ldÄ±.")

            # YENÄ°: Loop kapandÄ±ktan sonra PyAudio'yu sonlandÄ±r
            self.pya.terminate()
            print("PyAudio sonlandÄ±rÄ±ldÄ±.")

    async def _async_run(self):
        """Ana async fonksiyonu (v3.py'deki 'run' metodu gibi)"""
        tasks = set()
        try:
            async with self.client.aio.live.connect(
                model=self.MODEL, config=self.CONFIG
            ) as session:
                self.session = session
                self.status_changed.emit("BaÄŸlantÄ± kuruldu. Dinlemeye hazÄ±r!")

                self.audio_in_queue = asyncio.Queue()
                self.audio_out_queue = asyncio.Queue(maxsize=100)

                tasks.add(asyncio.create_task(self._send_realtime()))
                tasks.add(asyncio.create_task(self._listen_audio()))
                tasks.add(asyncio.create_task(self._receive_audio()))
                tasks.add(asyncio.create_task(self._play_audio()))

                await asyncio.gather(*tasks)

        except (asyncio.CancelledError, KeyboardInterrupt):
            print("\nAsync run sonlandÄ±rÄ±lÄ±yor (CancelledError)...")
        except Exception as e:
            print(f"Ana '_async_run' dÃ¶ngÃ¼sÃ¼nde hata: {e}")
            self.error_occurred.emit(f"BaÄŸlantÄ± hatasÄ±: {e}")
        finally:
            print("TÃ¼m async gÃ¶revler iptal ediliyor...")
            for task in tasks:
                if not task.done():
                    task.cancel()
            if tasks:
                # TÃ¼m alt gÃ¶revlerin iptal iÅŸlemini bitirmesini bekle
                await asyncio.gather(*tasks, return_exceptions=True)
            print("Async gÃ¶revler temizlendi.")

            # YENÄ°: BÃ¼tÃ¼n async iÅŸ bittikten sonra loop'u durdur
            if self.loop and self.loop.is_running():
                self.loop.call_soon_threadsafe(self.loop.stop)

    async def _send_realtime(self):
        """Kuyruktaki ses verisini Gemini'a gÃ¶nderir (v3.py'den)"""
        while True:
            try:
                msg = await self.audio_out_queue.get()
                blob = types.Blob(
                    data=msg["data"],
                    mime_type=msg.get("mime_type", "audio/pcm;rate=16000"),
                )
                await self.session.send_realtime_input(audio=blob)
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"_send_realtime hatasÄ±: {e}")

    async def _listen_audio(self):
        """Mikrofonu dinler ve kuyruÄŸa atar (v3.py'den)"""
        kwargs = {"exception_on_overflow": False} if __debug__ else {}
        mic_info = self.pya.get_default_input_device_info()

        while True:
            if not self.is_recording:
                await asyncio.sleep(0.01)
                continue

            stream = None
            try:
                # Stream aÃ§Ä±lÄ±ÅŸÄ±
                if not self.is_recording:
                    continue
                stream = await asyncio.to_thread(
                    self.pya.open,
                    format=self.FORMAT,
                    channels=self.CHANNELS,
                    rate=self.SEND_SAMPLE_RATE,
                    input=True,
                    input_device_index=mic_info["index"],
                    frames_per_buffer=self.CHUNK_SIZE,
                )
                print("Stream aÃ§Ä±ldÄ±, dinleniyor...")

                # Okuma dÃ¶ngÃ¼sÃ¼
                while self.is_recording:
                    try:
                        data = await asyncio.to_thread(
                            stream.read, self.CHUNK_SIZE, **kwargs
                        )
                        await self.audio_out_queue.put(
                            {"data": data, "mime_type": "audio/pcm"}
                        )
                    except IOError as e:
                        if getattr(e, "errno", None) == pyaudio.paInputOverflowed:
                            continue
                        break
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Bilinmeyen _listen_audio hatasÄ±: {e}")
            finally:
                if stream:
                    await asyncio.to_thread(stream.stop_stream)
                    await asyncio.to_thread(stream.close)
                    print("Stream kapatÄ±ldÄ±.")

    async def _receive_audio(self):
        """Modelden gelen yanÄ±tlarÄ± (ses, metin, tool) iÅŸler (v3.py'den)"""
        while True:
            try:
                turn = self.session.receive()

                # YENÄ°: Bu 'turn'Ã¼n bir onay isteÄŸi olup olmadÄ±ÄŸÄ±nÄ± takip et
                is_confirmation_request = False

                async for chunk in turn:
                    # 1. Sunucu Ä°Ã§eriÄŸi (Ses veya Metin)
                    if chunk.server_content:
                        if data := chunk.data:
                            self.audio_in_queue.put_nowait(data)
                        if text := chunk.text:
                            print(f"AI: {text}", end="")
                            # GUI'yi metin hakkÄ±nda bilgilendir
                            self.response_received.emit(f"ğŸ“ AI: {text}")

                    # 2. AraÃ§ Ã‡aÄŸrÄ±sÄ± (Function Call)
                    elif chunk.tool_call:
                        print(f"\n[ğŸ”„ AraÃ§ Ã‡aÄŸrÄ±sÄ± AlgÄ±landÄ±]")
                        self.response_received.emit(f"[ğŸ”„ AraÃ§ Ã‡aÄŸrÄ±sÄ± AlgÄ±landÄ±...]")
                        function_responses_to_send = []

                        for fc in chunk.tool_call.function_calls:
                            try:
                                args = fc.args

                                # --- YENÄ° KISIM (DUYGU YAKALAMA) ---
                                # 'sense_of_response' aracÄ±nÄ± ilk olarak iÅŸle.
                                # Bu aracÄ±n 'should_execute' mantÄ±ÄŸÄ± yoktur.
                                if fc.name == "sense_of_response":
                                    emotion = args.get("emotion")
                                    if emotion:
                                        # Ä°stenen: Sadece print et
                                        print(
                                            f"--- ğŸ¤– MODEL DUYGUSU: {emotion.upper()} ---"
                                        )
                                        self.response_received.emit(
                                            f"ğŸ¤– Duygu: {emotion}"
                                        )

                                        # Modele bu aracÄ±n "baÅŸarÄ±yla" Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± bildir
                                        function_responses_to_send.append(
                                            types.FunctionResponse(
                                                id=fc.id,
                                                name=fc.name,
                                                response={
                                                    "success": True,
                                                    "emotion_registered": emotion,
                                                },
                                            )
                                        )
                                    continue  # Bu fonksiyon Ã§aÄŸrÄ±sÄ± iÅŸlendi, dÃ¶ngÃ¼de sonrakine geÃ§.
                                # --- YENÄ° KISIM SONU ---

                                # 'should_execute' gerektiren diÄŸer araÃ§lar (IoT, Nav)
                                should_execute = args.get("should_execute", False)

                                if not should_execute:
                                    print(f"â“ Model '{fc.name}' iÃ§in onay istiyor.")
                                    self.response_received.emit(
                                        f"â“ Model '{fc.name}' iÃ§in onay istiyor."
                                    )
                                    is_confirmation_request = (
                                        True  # <-- YENÄ°: Onay istediÄŸini iÅŸaretle
                                    )
                                    continue

                                response_data = {
                                    "success": False,
                                    "message": "Bilinmeyen fonksiyon",
                                }

                                # Durum 1: IoT
                                if fc.name == "control_iot_device":
                                    target = args.get("target_device_code")
                                    action = args.get("action")
                                    print(
                                        f"âœ… Onay alÄ±ndÄ±. IoT: {target} '{action}' yÃ¼rÃ¼tÃ¼lÃ¼yor..."
                                    )
                                    self.response_received.emit(
                                        f"âœ… IoT: {target} '{action}' yÃ¼rÃ¼tÃ¼lÃ¼yor..."
                                    )
                                    success, message = await asyncio.to_thread(
                                        self.execute_iot_command, target, action
                                    )
                                    response_data = {
                                        "success": success,
                                        "message": message,
                                    }

                                # Durum 2: Navigasyon
                                elif fc.name == "navigate_to_station":
                                    target = args.get("target_station")
                                    print(
                                        f"âœ… Onay alÄ±ndÄ±. Navigasyon: {target} hedefine yÃ¶nlendiriliyor..."
                                    )
                                    self.response_received.emit(
                                        f"âœ… Navigasyon: {target} hedefine yÃ¶nlendiriliyor..."
                                    )
                                    success, message = await asyncio.to_thread(
                                        self.execute_navigation_command, target
                                    )
                                    response_data = {
                                        "success": success,
                                        "message": message,
                                    }

                                # --- YÃ¼rÃ¼tme Bitti ---
                                self.response_received.emit(
                                    f"âœ… SonuÃ§: {response_data['message']}"
                                )
                                function_responses_to_send.append(
                                    types.FunctionResponse(
                                        id=fc.id, name=fc.name, response=response_data
                                    )
                                )
                            except Exception as e:
                                print(f"âŒ Fonksiyon iÅŸleme hatasÄ±: {e}")
                                self.error_occurred.emit(f"Fonksiyon hatasÄ±: {e}")
                                function_responses_to_send.append(
                                    types.FunctionResponse(
                                        id=fc.id,
                                        name=fc.name,
                                        response={"success": False, "message": str(e)},
                                    )
                                )

                        if function_responses_to_send:
                            print(
                                f"[ğŸ“¬ {len(function_responses_to_send)} adet fonksiyon yanÄ±tÄ± gÃ¶nderiliyor...]"
                            )
                            await self.session.send_tool_response(
                                function_responses=function_responses_to_send
                            )
                print("Turn tamamlandÄ±.")

                # YENÄ° (GÃœNCELLENDÄ°): UI'Ä± 'hazÄ±r' durumuna dÃ¶ndÃ¼rme mantÄ±ÄŸÄ±

                # 1. Barge-in kontrolÃ¼:
                # EÄŸer kullanÄ±cÄ± 'turn' biterken ZATEN konuÅŸmaya baÅŸladÄ±ysa (self.is_recording == True),
                # bu bir barge-in'dir. UI'Ä± 'hazÄ±r' moduna dÃ¶ndÃ¼rme, Ã§Ã¼nkÃ¼ zaten 'dinliyor' modunda olmalÄ±.
                if self.is_recording:
                    print("Barge-in algÄ±landÄ±: 'turn_finished' sinyali gÃ¶nderilmedi.")
                    continue  # Bir sonraki 'turn'Ã¼ (session.receive()) beklemeye baÅŸla

                # 2. Onay isteÄŸi kontrolÃ¼:
                # EÄŸer bu bir onay isteÄŸi idiyse ('evet/hayÄ±r' bekleniyor),
                # UI'Ä± 'hazÄ±r' moduna dÃ¶ndÃ¼rme, Ã§Ã¼nkÃ¼ 'iÅŸleniyor' (onay bekliyor) modunda kalmalÄ±.
                if is_confirmation_request:
                    print("Onay isteÄŸi: 'turn_finished' sinyali gÃ¶nderilmedi.")
                    continue  # Bir sonraki 'turn'Ã¼ (kullanÄ±cÄ±nÄ±n onayÄ±) beklemeye baÅŸla

                # 3. Normal bitiÅŸ:
                # Turn normal bittiyse (barge-in yok, onay isteÄŸi yok),
                # UI'Ä± 'hazÄ±r' durumuna dÃ¶ndÃ¼rmek iÃ§in sinyal gÃ¶nder.
                print("Turn normal bitti: 'turn_finished' sinyali gÃ¶nderiliyor.")
                self.turn_finished.emit()

            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"Hata: '_receive_audio' akÄ±ÅŸÄ±nda sorun: {e}")
                self.error_occurred.emit(f"YanÄ±t alma hatasÄ±: {e}")
                await asyncio.sleep(1)

    async def _interrupt_playback(self):
        """Mevcut ses oynatmayÄ± anÄ±nda keser (barge-in) - GÃœVENLÄ° VERSÄ°YON"""
        print("Barge-in: Oynatma kesiliyor (mute + clear)...")

        # 1. Gelecekteki oynatmalarÄ± durdur
        self._playback_muted = True

        # 2. Kuyruktaki bekleyen sesleri temizle
        await self._clear_audio_queue_async()

        # 3. Stream'i kapatmÄ±yoruz. _play_audio'daki bayrak yeterli.
        print("Barge-in: Mute edildi ve kuyruk temizlendi.")

    async def _play_audio(self):
        """Gelen sesi oynatÄ±r (Basit ve saÄŸlam versiyon)"""
        stream = None
        try:
            stream = await asyncio.to_thread(
                self.pya.open,
                format=self.FORMAT,
                channels=self.CHANNELS,
                rate=self.RECEIVE_SAMPLE_RATE,
                output=True,
            )
            print("Ses oynatÄ±cÄ± (basit) hazÄ±r.")
            while True:
                # Kuyruktan bir ses parÃ§asÄ± al
                bytestream = await self.audio_in_queue.get()

                # Barge-in kontrolÃ¼:
                # EÄŸer kullanÄ±cÄ± ÅŸu an konuÅŸuyorsa VEYA playback manuel olarak susturulmuÅŸsa...
                if self._playback_muted or self.is_recording:
                    self.audio_in_queue.task_done()  # Sesi kuyruktan al ama Ã§alma (atla)
                    continue  # Bir sonraki ses parÃ§asÄ±nÄ± bekle

                # Kontrolleri geÃ§tiyse, sesi Ã§al
                await asyncio.to_thread(stream.write, bytestream)
                self.audio_in_queue.task_done()

        except asyncio.CancelledError:
            print("Ses oynatÄ±cÄ± (basit) iptal edildi.")
        except Exception as e:
            print(f"Ses oynatÄ±cÄ± (basit) hatasÄ±: {e}")
            self.error_occurred.emit(f"Ses oynatma hatasÄ±: {e}")
        finally:
            # GÃ¶rev bittiÄŸinde stream'i gÃ¼venle kapat
            if stream:
                await asyncio.to_thread(stream.stop_stream)
                await asyncio.to_thread(stream.close)
            print("Ses oynatÄ±cÄ± (basit) kapatÄ±ldÄ±.")

    async def _clear_audio_queue_async(self):
        """Async olarak gelen ses kuyruÄŸunu temizler (Barge-in iÃ§in)"""
        if self.audio_in_queue is None:
            return
        try:
            while True:
                self.audio_in_queue.get_nowait()
                self.audio_in_queue.task_done()
        except asyncio.QueueEmpty:
            pass

    # --- GUI TarafÄ±ndan Ã‡aÄŸrÄ±lan Slotlar ---

    @Slot()
    def start_recording(self):
        """GUI 'BaÅŸlat' butonuna bastÄ±ÄŸÄ±nda tetiklenir."""
        if self.is_recording or not self.session or not self.loop:
            return

        print("ğŸ”´ KayÄ±t baÅŸlÄ±yor (GUI)...")
        self.is_recording = True

        # YENÄ°: Barge-in iÅŸlemini (sesi kes) async olarak tetikle
        asyncio.run_coroutine_threadsafe(self._interrupt_playback(), self.loop)

        # Gemini'a 'konuÅŸmaya baÅŸladÄ±m' sinyali gÃ¶nder (v3.py'deki gibi)
        coro = self.session.send_realtime_input(activity_start=types.ActivityStart())
        asyncio.run_coroutine_threadsafe(coro, self.loop)

    @Slot()
    def stop_processing(self):
        """GUI 'Durdur' butonuna bastÄ±ÄŸÄ±nda tetiklenir."""
        if not self.is_recording or not self.session or not self.loop:
            return

        print("âšª KayÄ±t durdu (GUI). Ä°ÅŸleniyor...")
        self.is_recording = False
        self._playback_muted = False  # YENÄ°: Modelin konuÅŸmasÄ±na tekrar izin ver

        # Gemini'a 'konuÅŸmam bitti' sinyali gÃ¶nder (v3.py'deki gibi)
        coro = self.session.send_realtime_input(activity_end=types.ActivityEnd())
        asyncio.run_coroutine_threadsafe(coro, self.loop)

    @Slot()
    def stop(self):
        """Uygulama kapandÄ±ÄŸÄ±nda ana async gÃ¶reve iptal sinyali gÃ¶nderir."""
        print("Worker stop Ã§aÄŸrÄ±ldÄ±.")
        if self.main_async_task and self.loop and self.loop.is_running():
            try:
                # Sadece ana gÃ¶revin iptalini iste, loop'u durdurma
                self.loop.call_soon_threadsafe(self.main_async_task.cancel)
            except RuntimeError as e:
                print(
                    f"GÃ¶rev iptal edilirken hata (muhtemelen loop zaten kapanmÄ±ÅŸ): {e}"
                )
            except Exception as e:
                print(f"GÃ¶rev iptal edilirken bilinmeyen hata: {e}")
        # loop.stop() ve pya.terminate() BURADAN KALDIRILDI.


# --- PySide6 GUI SÄ±nÄ±flarÄ± (enhanced.py'den) ---
# (Minimal deÄŸiÅŸiklikler yapÄ±ldÄ±, Ã§oÄŸunlukla aynÄ±)


class AnimatedMicButton(QPushButton):
    """Ã–zel animasyonlu mikrofon butonu"""

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setFixedSize(140, 140)
        self.setObjectName("micButton")
        self.is_listening = False
        self.breath_timer = QTimer(self)
        self.breath_timer.timeout.connect(self.update_breath)
        self.breath_value = 0
        self.breath_direction = 1
        self.stop_listening_animation()  # BaÅŸlangÄ±Ã§ stili

        shadow = QGraphicsDropShadowEffect()
        shadow.setBlurRadius(25)
        shadow.setColor(QColor(0, 0, 0, 100))
        shadow.setOffset(0, 8)
        self.setGraphicsEffect(shadow)

    def start_listening_animation(self):
        self.is_listening = True
        self.breath_timer.start(80)
        self.setStyleSheet(
            """
            QPushButton#micButton {
                border: 4px solid #F44336; border-radius: 70px;
                background: qradialgradient(cx:0.5, cy:0.5, radius:0.8, stop:0 #EF5350, stop:1 #F44336);
                color: white; font-size: 16px; font-weight: bold;
            }"""
        )

    def stop_listening_animation(self):
        self.is_listening = False
        self.breath_timer.stop()
        self.setFixedSize(140, 140)  # Boyutu sÄ±fÄ±rla
        self.setStyleSheet(
            """
            QPushButton#micButton {
                border: 4px solid #4CAF50; border-radius: 70px;
                background: qradialgradient(cx:0.5, cy:0.5, radius:0.8, stop:0 #81C784, stop:1 #4CAF50);
                color: white; font-size: 16px; font-weight: bold;
            }
            QPushButton#micButton:hover {
                background: qradialgradient(cx:0.5, cy:0.5, radius:0.8, stop:0 #A5D6A7, stop:1 #66BB6A);
            }"""
        )

    def update_breath(self):
        if not self.is_listening:
            return
        self.breath_value += self.breath_direction * 3
        if self.breath_value >= 20:
            self.breath_direction = -1
        elif self.breath_value <= 0:
            self.breath_direction = 1
        new_size = 140 + int(self.breath_value * 0.2)
        self.setFixedSize(new_size, new_size)


class EnhancedVoiceAssistantGUI(QMainWindow):
    """Ana uygulama penceresi"""

    def __init__(self):
        super().__init__()
        self.is_listening = False
        self.worker_thread = None
        self.worker = None
        self.setupUI()
        self.setup_worker()

    def setupUI(self):
        self.setWindowTitle("ğŸ¤ Beezy Assistant AI - v2 (Streaming)")
        self.setFixedSize(650, 750)
        self.setStyleSheet(
            "QMainWindow { background: qlineargradient(x1:0, y1:0, x2:0, y2:1, stop:0 #F8F9FA, stop:1 #E9ECEF); }"
        )

        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QVBoxLayout(central_widget)
        main_layout.setContentsMargins(40, 40, 40, 40)
        main_layout.setSpacing(25)

        title_label = QLabel("ğŸ¤ Beezy Assistant AI")
        title_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        title_label.setStyleSheet(
            "QLabel { color: #2E7D32; font-size: 32px; font-weight: bold; padding: 25px; margin-bottom: 10px; }"
        )

        self.status_label = QLabel("BaÅŸlatÄ±lÄ±yor...")
        self.status_label.setAlignment(Qt.AlignmentFlag.AlignCenter)
        self.status_label.setStyleSheet(
            "QLabel { color: #666; font-size: 18px; padding: 15px; background-color: white; border-radius: 12px; border: 2px solid #E0E0E0; margin: 10px; }"
        )

        mic_container = QWidget()
        mic_layout = QHBoxLayout(mic_container)
        mic_layout.setAlignment(Qt.AlignmentFlag.AlignCenter)
        mic_layout.setContentsMargins(0, 20, 0, 20)
        self.mic_button = AnimatedMicButton()
        self.mic_button.setText("ğŸ¤ Bas KonuÅŸ")
        self.mic_button.clicked.connect(self.toggle_listening)
        self.mic_button.setEnabled(False)
        mic_layout.addWidget(self.mic_button)

        self.response_area = QTextEdit()
        self.response_area.setReadOnly(True)
        self.response_area.setPlaceholderText(
            "ğŸ”Š Sesli yanÄ±tlar hoparlÃ¶rden oynatÄ±lacak...\n\nğŸ“ Aktivite logu burada gÃ¶rÃ¼necek..."
        )
        self.response_area.setStyleSheet(
            "QTextEdit { border: 2px solid #E0E0E0; border-radius: 12px; padding: 20px; font-size: 15px; background-color: white; }"
        )
        self.response_area.setMinimumHeight(250)

        instructions = QLabel(
            "ğŸ™ï¸ Mikrofona tÄ±kla â†’ KonuÅŸ â†’ Tekrar tÄ±kla â†’ ğŸ”Š YanÄ±tÄ± dinle"
        )
        instructions.setAlignment(Qt.AlignmentFlag.AlignCenter)
        instructions.setStyleSheet(
            "QLabel { color: #888; font-size: 14px; font-style: italic; padding: 15px; background-color: #F5F5F5; border-radius: 8px; border: 1px solid #DDD; }"
        )

        main_layout.addWidget(title_label)
        main_layout.addWidget(self.status_label)
        main_layout.addWidget(mic_container)
        main_layout.addWidget(self.response_area, 1)
        main_layout.addWidget(instructions)

    def setup_worker(self):
        """Worker thread'i kurar ve baÅŸlatÄ±r."""
        self.worker_thread = QThread()
        self.worker = GeminiLiveWorker()
        self.worker.moveToThread(self.worker_thread)

        # Sinyalleri baÄŸla
        self.worker.status_changed.connect(self.update_status)
        self.worker.response_received.connect(self.add_response)
        self.worker.error_occurred.connect(self.handle_error)
        self.worker.turn_finished.connect(self.on_turn_finished)  # <-- YENÄ° BAÄLANTI

        # Thread baÅŸladÄ±ÄŸÄ±nda 'run_async_loop' fonksiyonunu tetikle
        self.worker_thread.started.connect(self.worker.run_async_loop)

        # Thread'i kapatma sinyallerini baÄŸla
        self.worker_thread.finished.connect(self.worker.deleteLater)
        self.worker_thread.finished.connect(self.worker_thread.deleteLater)

        # Thread'i baÅŸlat (bu, 'run_async_loop'u tetikleyecek)
        self.worker_thread.start()

        # ArayÃ¼zÃ¼ etkinleÅŸtirmek iÃ§in kÃ¼Ã§Ã¼k bir gecikme
        QTimer.singleShot(1000, lambda: self.update_status("Asistan baÅŸlatÄ±lÄ±yor..."))

    @Slot()
    def toggle_listening(self):
        if not self.is_listening:
            self.start_listening()
        else:
            self.stop_listening()

    def start_listening(self):
        self.is_listening = True
        self.mic_button.start_listening_animation()
        self.mic_button.setText("ğŸ”´ Dinliyorum...")
        self.status_label.setStyleSheet(
            "QLabel { color: #F44336; font-size: 18px; font-weight: bold; padding: 15px; background-color: #FFEBEE; border-radius: 12px; border: 2px solid #F44336; margin: 10px; }"
        )

        # Worker'a 'baÅŸlat' komutu gÃ¶nder
        self.worker.start_recording()

    def stop_listening(self):
        """Stop listening and start processing"""
        self.is_listening = False
        self.mic_button.stop_listening_animation()
        self.mic_button.setText("ğŸ¤” Ä°ÅŸleniyor...")
        # self.mic_button.setEnabled(False) <-- KÄ°LÄ°T KALDIRILDI!
        self.status_label.setStyleSheet(
            """
            QLabel {
                color: #FFA000; font-size: 18px; font-weight: bold; 
                padding: 15px; background-color: #FFF8E1; 
                border-radius: 12px; border: 2px solid #FFA000; margin: 10px;
            }
        """
        )

        # Worker'a 'durdur' komutu gÃ¶nder
        self.worker.stop_processing()

    @Slot(str)
    def update_status(self, status: str):
        self.status_label.setText(status)

        if "Dinlemeye hazÄ±r" in status:
            self.status_label.setStyleSheet(
                "QLabel { color: #4CAF50; font-size: 18px; font-weight: bold; padding: 15px; background-color: #E8F5E8; border-radius: 12px; border: 2px solid #4CAF50; margin: 10px; }"
            )
            self.mic_button.setText("ğŸ¤ Bas KonuÅŸ")
            self.mic_button.setEnabled(True)
            self.mic_button.stop_listening_animation()
            self.is_listening = False

    @Slot(str)
    def add_response(self, response: str):
        """Aktivite loguna yanÄ±tÄ± ekler"""
        timestamp = time.strftime("%H:%M:%S")
        self.response_area.append(f"[{timestamp}] {response}")
        self.response_area.ensureCursorVisible()

        # ArtÄ±k UI sÄ±fÄ±rlama iÅŸini bu fonksiyon yapmayacak.
        # 'on_turn_finished' sinyali bu iÅŸi daha gÃ¼venilir yapÄ±yor.

    @Slot()
    def on_turn_finished(self):
        """
        Worker'dan 'turn bitti' (hem ses hem araÃ§ Ã§aÄŸrÄ±sÄ±) sinyali geldiÄŸinde tetiklenir.
        Bu, UI'Ä± 'HazÄ±r' durumuna dÃ¶ndÃ¼rmek iÃ§in en gÃ¼venilir yerdir.
        """
        print("GUI: Turn bitti sinyali alÄ±ndÄ±. ArayÃ¼z 'HazÄ±r' durumuna getiriliyor.")
        # 'stop_listening' iÃ§inde devre dÄ±ÅŸÄ± bÄ±rakÄ±lan butonu
        # ve durumu gÃ¼venle sÄ±fÄ±rlar.
        self.update_status("Dinlemeye hazÄ±r!")

    @Slot(str)
    def handle_error(self, error_message: str):
        self.update_status(f"Hata: {error_message}")
        timestamp = time.strftime("%H:%M:%S")
        self.response_area.append(f"[{timestamp}] âŒ HATA: {error_message}")

        # ArayÃ¼zÃ¼ sÄ±fÄ±rla
        self.is_listening = False
        self.mic_button.stop_listening_animation()
        self.mic_button.setText("ğŸ¤ Bas KonuÅŸ")
        self.mic_button.setEnabled(True)

        QMessageBox.warning(self, "Hata", error_message)

    def closeEvent(self, event):
        """Uygulama kapanÄ±rken thread'i gÃ¼venle durdurur."""
        print("Kapatma olayÄ± tetiklendi.")
        if self.worker:
            self.worker.stop()
        if self.worker_thread:
            self.worker_thread.quit()
            if not self.worker_thread.wait(3000):  # 3 saniye bekle
                print("Thread zamanÄ±nda durmadÄ±, sonlandÄ±rÄ±lÄ±yor.")
                self.worker_thread.terminate()
        event.accept()


def main():
    load_dotenv()
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ Hata: GOOGLE_API_KEY bulunamadÄ±!")
        return

    app = QApplication(sys.argv)
    window = EnhancedVoiceAssistantGUI()
    window.show()

    print("ğŸš€ BeezyAssistant AI v2 (Streaming) GUI baÅŸlatÄ±ldÄ±!")
    sys.exit(app.exec())


if __name__ == "__main__":
    main()
